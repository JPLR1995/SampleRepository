{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using APIs in Projects\n",
    "\n",
    "\n",
    "When getting data from APIs, I strongly suggest following a three-step workflow:\n",
    "\n",
    "1. Write some code that gets data from an API and saves all of the data (if possible) to a file\n",
    "2. Write a second program (usually a second file) that loads the data from the API, extracts the data that will be useful for analysis, and saves it in a flat file (typically a CSV).\n",
    "3. Program number 3 loads the CSV file and does the analysis\n",
    "\n",
    "This approach has a few important benefits.\n",
    "\n",
    "The first and most important is that often it is difficult to get the same raw data again. If you are using Twitter, then the Search API only lets you get the last week. If you are doing analysis a month down the road and decide that you really wish you had saved metadata about the number of retweets, it is too late. By saving the raw data you can change your measures or analysis strategy and still have access to the data.\n",
    "\n",
    "The second is that this gives you a nice pipeline, with intermediate files. Instead of including the entire raw data file in the code that does analysis, you only have to load the CSV, which is often much smaller and easier to work with.\n",
    "\n",
    "This brief lesson will show an example of this workflow, using `tweepy`.\n",
    "\n",
    "Note that I'm going to put everything in one file for convenience, but my typical workflow is to put these in separate files and then run each file separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program 1 - Data Retrieval\n",
    "\n",
    "The goal of our project is to produce a visualization of the histogram of the number of retweets for recent tweets about President Trump. The first program gets tweets about President Trump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "from twitter_authentication import CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list to store the results\n",
    "results = []\n",
    "for tweet in tweepy.Cursor(api.search, \n",
    "                           q='Trump -filter:retweets', # only get the original tweets\n",
    "                           tweet_mode = 'extended',\n",
    "                           count=200).items(5000): # Change this to as high as you like, if you have time :)\n",
    "    results.append(tweet._json)\n",
    "    #print(tweet.user.screen_name + \"\\t\" + str(tweet.created_at) + \"\\t\" + tweet.full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, write the results to a file\n",
    "with open('raw_trump_tweets.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program 2 - Data Cleaning\n",
    "\n",
    "This program loads the saved raw data, grabs what we want, and converts it into a csv.\n",
    "\n",
    "I decided to save the timestamp, text, and retweet and favorite counts.\n",
    "\n",
    "This is also where you typically would do more complicated measure creation. Here I show how to create a measure of tweet_length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw_trump_tweets.json', 'r') as f:\n",
    "    tweets = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Thu May 27 22:05:53 +0000 2021',\n",
       " 'id': 1398037772615798786,\n",
       " 'id_str': '1398037772615798786',\n",
       " 'full_text': \"@OneCrazyCat2 @ifsaica @DavidPriess You mean Trump and God aren't the same person? ðŸ¤£ðŸ¤£ But seriously, this dude should retire but he won't. It is about control and money for politicians. They don't care about right and wrong, or us. These are the politicians that make me oppose the conservatives anymore.\",\n",
       " 'truncated': False,\n",
       " 'display_text_range': [36, 304],\n",
       " 'entities': {'hashtags': [],\n",
       "  'symbols': [],\n",
       "  'user_mentions': [{'screen_name': 'OneCrazyCat2',\n",
       "    'name': 'OneCrazyCat',\n",
       "    'id': 1147210856775766016,\n",
       "    'id_str': '1147210856775766016',\n",
       "    'indices': [0, 13]},\n",
       "   {'screen_name': 'ifsaica',\n",
       "    'name': 'Alexander - Hebrews 13:5-6',\n",
       "    'id': 55489838,\n",
       "    'id_str': '55489838',\n",
       "    'indices': [14, 22]},\n",
       "   {'screen_name': 'DavidPriess',\n",
       "    'name': 'David Priess',\n",
       "    'id': 2521546890,\n",
       "    'id_str': '2521546890',\n",
       "    'indices': [23, 35]}],\n",
       "  'urls': []},\n",
       " 'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
       " 'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>',\n",
       " 'in_reply_to_status_id': 1397998824904441861,\n",
       " 'in_reply_to_status_id_str': '1397998824904441861',\n",
       " 'in_reply_to_user_id': 1147210856775766016,\n",
       " 'in_reply_to_user_id_str': '1147210856775766016',\n",
       " 'in_reply_to_screen_name': 'OneCrazyCat2',\n",
       " 'user': {'id': 1388560929655242752,\n",
       "  'id_str': '1388560929655242752',\n",
       "  'name': 'GreyFox24',\n",
       "  'screen_name': 'Fox24Grey',\n",
       "  'location': '',\n",
       "  'description': '',\n",
       "  'url': None,\n",
       "  'entities': {'description': {'urls': []}},\n",
       "  'protected': False,\n",
       "  'followers_count': 0,\n",
       "  'friends_count': 1,\n",
       "  'listed_count': 0,\n",
       "  'created_at': 'Sat May 01 18:28:28 +0000 2021',\n",
       "  'favourites_count': 1,\n",
       "  'utc_offset': None,\n",
       "  'time_zone': None,\n",
       "  'geo_enabled': False,\n",
       "  'verified': False,\n",
       "  'statuses_count': 13,\n",
       "  'lang': None,\n",
       "  'contributors_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'is_translation_enabled': False,\n",
       "  'profile_background_color': 'F5F8FA',\n",
       "  'profile_background_image_url': None,\n",
       "  'profile_background_image_url_https': None,\n",
       "  'profile_background_tile': False,\n",
       "  'profile_image_url': 'http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png',\n",
       "  'profile_image_url_https': 'https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png',\n",
       "  'profile_link_color': '1DA1F2',\n",
       "  'profile_sidebar_border_color': 'C0DEED',\n",
       "  'profile_sidebar_fill_color': 'DDEEF6',\n",
       "  'profile_text_color': '333333',\n",
       "  'profile_use_background_image': True,\n",
       "  'has_extended_profile': True,\n",
       "  'default_profile': True,\n",
       "  'default_profile_image': True,\n",
       "  'following': False,\n",
       "  'follow_request_sent': False,\n",
       "  'notifications': False,\n",
       "  'translator_type': 'none',\n",
       "  'withheld_in_countries': []},\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'place': None,\n",
       " 'contributors': None,\n",
       " 'is_quote_status': False,\n",
       " 'retweet_count': 0,\n",
       " 'favorite_count': 0,\n",
       " 'favorited': False,\n",
       " 'retweeted': False,\n",
       " 'lang': 'en'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('cleaned_data.csv', 'w', \n",
    "          encoding='UTF-8',\n",
    "          newline='') as fn:\n",
    "    f = csv.writer(fn)\n",
    "    f.writerow(['created_at',\n",
    "                'tweet_text',\n",
    "                'retweets',\n",
    "                'favorites',\n",
    "                'tweet_length'\n",
    "               ])\n",
    "    for tweet in tweets:\n",
    "        f.writerow([tweet['created_at'], \n",
    "                    tweet['full_text'],\n",
    "                    tweet['retweet_count'],\n",
    "                    tweet['favorite_count'],\n",
    "                    len(tweet['full_text'])\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program 3 - Data Analysis\n",
    "\n",
    "Here we use pandas to load the data and analyze it. This could include statistical tests. Here, I'm just visualizing the distribution of retweets and the relationship between retweets and length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just make sure it looks OK.\n",
    "df.sort_values('retweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.retweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, it's super skewed, with most tweets never getting retweeted while a few get tons of retweets.\n",
    "\n",
    "Let's see if it changes if we get rid of the tweets that never got retweeted (like, maybe we have a principled reason to believe they are different than other tweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.loc[df.retweets > 0, 'retweets'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I thought, this is a somewhat \"scale-free\" distribution, meaning wherever you zoom in, you see the same pattern. Try changing the `0` up above to any (small) number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fun, let's also look at the relationship between retweets and tweet length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(y='retweets', x='tweet_length', data = df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because retweets are so skewed, let's log them\n",
    "p = sns.jointplot(y=np.log(df.retweets + 1), x='tweet_length', data = df)\n",
    "p.set_axis_labels('Tweet Length','Retweets (log)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 9 Coding Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program 1 - Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting ready API\n",
    "import tweepy\n",
    "import json\n",
    "from twitter_authentication import CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the raw results in a file\n",
    "results_climate_change = []\n",
    "results_global_warming = []\n",
    "for tweet in tweepy.Cursor(api.search, \n",
    "                           q = '\"climate change\" -filter:retweets',\n",
    "                           tweet_mode = 'extended',\n",
    "                           count = 200).items(10000):\n",
    "    results_climate_change.append(tweet._json)\n",
    "for tweet in tweepy.Cursor(api.search, \n",
    "                           q = '\"global warming\" -filter:retweets',\n",
    "                           tweet_mode = 'extended',\n",
    "                           count = 200).items(10000):\n",
    "    results_global_warming.append(tweet._json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving raw data into file\n",
    "with open('raw_climate_change.json', 'w') as f_cc:\n",
    "    json.dump(results_climate_change, f_cc)\n",
    "with open('raw_global_warming.json', 'w') as f_gb:\n",
    "    json.dump(results_global_warming, f_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program 2 - Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data of both files\n",
    "with open('raw_climate_change.json', 'r') as f_cc:\n",
    "    tweets_climate_change = json.load(f_cc)\n",
    "with open('raw_global_warming.json', 'r') as f_gb:\n",
    "    tweets_global_warming = json.load(f_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write tidy data into .csv files\n",
    "import csv\n",
    "with open('cleaned_data_climate_change.csv', 'w', \n",
    "          encoding='UTF-8',\n",
    "          newline='') as fn_cc:\n",
    "    f_cc = csv.writer(fn_cc)\n",
    "    f_cc.writerow(['created_at',\n",
    "                   'tweet_text',\n",
    "                   'retweets',\n",
    "                   'favorites',\n",
    "                   'tweet_length'\n",
    "                  ])\n",
    "    for tweet in tweets_climate_change:\n",
    "        f_cc.writerow([tweet['created_at'],\n",
    "                       tweet['full_text'],\n",
    "                       tweet['retweet_count'],\n",
    "                       tweet['favorite_count'],\n",
    "                       len(tweet['full_text'])\n",
    "                      ])\n",
    "        \n",
    "with open('cleaned_data_global_warming.csv', 'w', \n",
    "          encoding='UTF-8',\n",
    "          newline='') as fn_gb:\n",
    "    f_gb = csv.writer(fn_gb)\n",
    "    f_gb.writerow(['created_at',\n",
    "                   'tweet_text',\n",
    "                   'retweets',\n",
    "                   'favorites',\n",
    "                   'tweet_length'\n",
    "                  ])\n",
    "    for tweet in tweets_global_warming:\n",
    "        f_gb.writerow([tweet['created_at'],\n",
    "                       tweet['full_text'],\n",
    "                       tweet['retweet_count'],\n",
    "                       tweet['favorite_count'],\n",
    "                       len(tweet['full_text'])\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program 3 - Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing .csv files\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "df_climate_change = pd.read_csv('./cleaned_data_climate_change.csv')\n",
    "df_global_warming = pd.read_csv('./cleaned_data_global_warming.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sorting by retweets\n",
    "df_climate_change.sort_values('retweets')\n",
    "df_global_warming.sort_values('retweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Histograms of retweets\n",
    "sns.distplot(df_climate_change.retweets)\n",
    "sns.distplot(df_global_warming.retweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Histograms of retweets when retweets is greater than 100\n",
    "sns.distplot(df_climate_change.loc[df_climate_change.retweets > 100, 'retweets'])\n",
    "sns.distplot(df_global_warming.loc[df_global_warming.retweets > 100, 'retweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scatterplot of retweets vs. tweet length\n",
    "import numpy as np\n",
    "sns.jointplot(y='retweets', x='tweet_length', data = df_climate_change);\n",
    "sns.jointplot(y='retweets', x='tweet_length', data = df_global_warming);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#p = sns.jointplot(y=np.log(df_climate_change.retweets + 1), x='tweet_length', data = df_climate_change)\n",
    "#p.set_axis_labels('Tweet Length','Retweets (log)');\n",
    "p = sns.jointplot(y=np.log(df_global_warming.retweets + 1), x='tweet_length', data = df_global_warming)\n",
    "p.set_axis_labels('Tweet Length','Retweets (log)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env_climate_change = \"\"\n",
    "env_global_warming = \"\"\n",
    "for tweet in df_climate_change.tweet_text:\n",
    "    if \"environment\" in tweet:\n",
    "        env_climate_change = env_climate_change + \" \" + tweet\n",
    "for tweet in df_global_warming.tweet_text:\n",
    "    if \"environment\" in tweet:\n",
    "        env_global_warming = env_global_warming + \" \" + tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x11b675b40a0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS    \n",
    "\n",
    "wordcloud_climate_change = WordCloud(width = 800, height = 800,\n",
    "                                     background_color = 'white',\n",
    "                                     stopwords = set(STOPWORDS),\n",
    "                                     min_font_size = 10).generate(env_climate_change)\n",
    "\n",
    "wordcloud_global_warming = WordCloud(width = 800, height = 800,\n",
    "                                     background_color = 'white',\n",
    "                                     stopwords = set(STOPWORDS),\n",
    "                                     min_font_size = 10).generate(env_global_warming)\n",
    "\n",
    "wordcloud_climate_change.to_file(\"wordcloud_climate_change.png\")\n",
    "wordcloud_global_warming.to_file(\"wordcloud_global_warming.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
